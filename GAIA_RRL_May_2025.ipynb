{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e54f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import healpy as hp\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import lsdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import astropy.units as u\n",
    "import glob as glob\n",
    "\n",
    "import lsst.daf.butler as dafButler\n",
    "from lsst.analysis.ap import apdb\n",
    "from lsst.ap.association import AssociationTask, AssociationConfig\n",
    "from lsst.dax.apdb import Apdb, ApdbCassandra, ApdbTables\n",
    "import lsst.geom as geom\n",
    "from lsst.afw import image as afwImage\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy.visualization import ZScaleInterval, SqrtStretch, ImageNormalize, ManualInterval, AsinhStretch, MinMaxInterval, LogStretch\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from typing import TYPE_CHECKING, cast\n",
    "from pathlib import Path\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "plt.set_loglevel('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d122992",
   "metadata": {},
   "source": [
    "# Loading Vizier and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ee147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base directory where the files are\n",
    "base_dir = Path(\"/sdf/home/n/ncaplar\")\n",
    "\n",
    "# List of filenames\n",
    "filenames = [\"m49_period.tsv\"]\n",
    "\n",
    "# Column names based on your file structure\n",
    "column_names = [\n",
    "    '_RAJ2000', '_DEJ2000', 'Source', 'PF', 'P1O',\n",
    "    'Gmagavg', 'R21G', 'R31G', 'phi21G','phi31G', 'FundFreq1', 'FundFreq2', 'Class'\n",
    "]\n",
    "\n",
    "# Dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "for file in filenames:\n",
    "    file_path = base_dir / file\n",
    "    \n",
    "    # Read and find where the actual data starts\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('_RAJ2000|'):\n",
    "            start_idx = i\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        raise ValueError(f\"Could not find table header in {file}\")\n",
    "\n",
    "    data_start = start_idx + 3  # skip header + units + dashed lines\n",
    "\n",
    "    # Read the actual table\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=\"|\",\n",
    "        skiprows=data_start,\n",
    "        names=column_names,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "    dfs[file.replace(\".tsv\", \"\")] = df  # store with nice key like '212_m7'\n",
    "\n",
    "# Unpack individual DataFrames\n",
    "df_m49 = dfs[\"m49_period\"]\n",
    "\n",
    "# Example: print how many rows were loaded\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name}: {len(df)} rows loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ce075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directory where the files are\n",
    "base_dir = Path(\"/sdf/home/n/ncaplar\")\n",
    "\n",
    "# List of filenames\n",
    "filenames = [\"212_m7.tsv\", \"216_m17.tsv\", \"m49.tsv\"]\n",
    "\n",
    "# Column names based on your file structure\n",
    "column_names = [\n",
    "    '_RAJ2000', '_DEJ2000', 'Source', 'PF', 'P1O',\n",
    "    'Gmagavg', 'RA_ICRS', 'DE_ICRS'\n",
    "]\n",
    "\n",
    "# Dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "for file in filenames:\n",
    "    file_path = base_dir / file\n",
    "    \n",
    "    # Read and find where the actual data starts\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('_RAJ2000|'):\n",
    "            start_idx = i\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        raise ValueError(f\"Could not find table header in {file}\")\n",
    "\n",
    "    data_start = start_idx + 3  # skip header + units + dashed lines\n",
    "\n",
    "    # Read the actual table\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=\"|\",\n",
    "        skiprows=data_start,\n",
    "        names=column_names,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "    dfs[file.replace(\".tsv\", \"\")] = df  # store with nice key like '212_m7'\n",
    "\n",
    "# Unpack individual DataFrames\n",
    "df_212_m7 = dfs[\"212_m7\"]\n",
    "df_216_m17 = dfs[\"216_m17\"]\n",
    "df_m49 = dfs[\"m49\"]\n",
    "\n",
    "# Example: print how many rows were loaded\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name}: {len(df)} rows loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m49 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: time (MJD), mag_obs, mag_err\n",
    "# These must be numpy arrays of same length\n",
    "def fit_constrained_fourier(time, mag_obs, mag_err, period, R21, R31, phi21, phi31):\n",
    "    # Phase-fold the time\n",
    "    phase = (time % period) / period\n",
    "\n",
    "    # Define constrained model with only 3 free params\n",
    "    def constrained_model(phase, A0, A1, phi1):\n",
    "        A2 = R21 * A1\n",
    "        A3 = R31 * A1\n",
    "        phi2 = 2 * phi1 + phi21\n",
    "        phi3 = 3 * phi1 + phi31\n",
    "\n",
    "        return (\n",
    "            A0\n",
    "            + A1 * np.cos(2 * np.pi * 1 * phase + phi1)\n",
    "            + A2 * np.cos(2 * np.pi * 2 * phase + phi2)\n",
    "            + A3 * np.cos(2 * np.pi * 3 * phase + phi3)\n",
    "        )\n",
    "\n",
    "    # Initial guess\n",
    "    A0_init = np.median(mag_obs)\n",
    "    A1_init = 0.3\n",
    "    phi1_init = 0.0\n",
    "    p0 = [A0_init, A1_init, phi1_init]\n",
    "\n",
    "    # Fit\n",
    "    popt, _ = curve_fit(\n",
    "        constrained_model, phase, mag_obs, p0=p0,\n",
    "        sigma=mag_err, absolute_sigma=False, maxfev=10000\n",
    "    )\n",
    "\n",
    "    # Return fitted parameters and a model evaluation function\n",
    "    def model_function(ph):\n",
    "        return constrained_model(ph, *popt)\n",
    "\n",
    "    return popt, model_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mag_errors(sciFlux, sciFluxErr):\n",
    "    \"\"\"Convert flux into magnitudes and compute magnitude error with a lower limit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sciFlux : `float` or array-like\n",
    "        Science flux\n",
    "    sciFluxErr : `float` or array-like\n",
    "        Science flux error\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mag, magErr : `float` or array-like\n",
    "        Magnitude and magnitude error\n",
    "    \"\"\"\n",
    "    mag = u.nJy.to(u.ABmag, sciFlux)\n",
    "    upper_mag = u.nJy.to(u.ABmag, sciFlux + sciFluxErr)\n",
    "    lower_mag = u.nJy.to(u.ABmag, sciFlux - sciFluxErr)\n",
    "    magErr = -(upper_mag - lower_mag) / 2\n",
    "\n",
    "    # Enforce minimum error\n",
    "    magErr = np.maximum(magErr, 0.001)\n",
    "\n",
    "    return mag, magErr\n",
    "\n",
    "def create_mag(sciFlux):\n",
    "    \"\"\"Move flux into magnitudes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sciFlux : `float`\n",
    "        Science flux\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mag  : `float`\n",
    "        Magnitude\n",
    "    \"\"\"\n",
    "    \n",
    "    mag = u.nJy.to(u.ABmag, sciFlux)\n",
    "    \n",
    "    return mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3fd77b",
   "metadata": {},
   "source": [
    "# LSST butler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a133c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"embargo\"\n",
    "collection = \"LSSTCam/runs/DRP/20250415_20250422/d_2025_04_23/DM-50409\"\n",
    "instrument = \"LSSTCam\"\n",
    "\n",
    "butler = dafButler.Butler(repo, collections=collection, instrument=instrument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28be28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"embargo\"\n",
    "collection = \"LSSTCam/runs/DRP/20250420_20250429/w_2025_18/DM-50628\"\n",
    "collection_w19 = \"LSSTCam/runs/DRP/FL/w_2025_19/DM-50795\"\n",
    "instrument = \"LSSTCam\"\n",
    "\n",
    "butler = dafButler.Butler(repo, collections=collection, instrument=instrument)\n",
    "butler_w19 = dafButler.Butler(repo, collections=collection_w19, instrument=instrument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944550a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbe109",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_refs = butler.query_datasets(\"object\")\n",
    "\n",
    "diaobj_refs = butler.query_datasets(\"dia_object\")\n",
    "lc_refs = butler.query_datasets(\"dia_source\")\n",
    "diaobj_refs_w19 = butler_w19.query_datasets(\"dia_object\")\n",
    "lc_refs_w19 = butler_w19.query_datasets(\"dia_source\")\n",
    "\n",
    "print(len(obj_refs))\n",
    "print(len(diaobj_refs))\n",
    "print(len(lc_refs))\n",
    "\n",
    "print(len(diaobj_refs_w19))\n",
    "print(len(lc_refs_w19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "verbose = False\n",
    "\n",
    "for band in bands:\n",
    "    try:\n",
    "        datasetRefs_dia = list(\n",
    "            butler.query_datasets(\n",
    "                \"dia_source_detector\",\n",
    "                where=f\"band='{band}'\",\n",
    "                limit=None  # Remove dataset limit\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying band '{band}': {e}\")\n",
    "        datasetRefs_dia = []\n",
    "\n",
    "    if verbose and datasetRefs_dia:\n",
    "        print(f\"\\nDataset references for band '{band}':\")\n",
    "        for dr in datasetRefs_dia:\n",
    "            print(dr)\n",
    "\n",
    "    print(f\"Found {len(datasetRefs_dia)} dia_source_detector datasets for band '{band}'\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Initialize list to hold object DataFrames\n",
    "object_list = []\n",
    "\n",
    "# Loop over tracts via obj_refs\n",
    "for obj_ref in tqdm(obj_refs):\n",
    "    try:\n",
    "        # Load full object table for this tract\n",
    "        table = butler.get(\"object\", dataId=obj_ref.dataId, parameters={'columns': ['objectId', 'tract', 'patch',\n",
    "                                                                                    'u_ra', 'u_dec', 'u_psfFlux', 'u_psfFluxErr',\n",
    "                                                                                    'g_ra', 'g_dec', 'g_psfFlux', 'g_psfFluxErr',\n",
    "                                                                                    'r_ra', 'r_dec', 'r_psfFlux', 'r_psfFluxErr',\n",
    "                                                                                    'i_ra', 'i_dec', 'i_psfFlux', 'i_psfFluxErr']})\n",
    "        # table = butler.get(\"object\", dataId=obj_ref.dataId)\n",
    "        df = table.to_pandas()\n",
    "        object_list.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: objectTable_tract not found for tract {obj_ref.dataId['tract']}. Skipping.\")\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "objects = pd.concat(object_list, ignore_index=True) if object_list else pd.DataFrame()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab141337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "objects['mean_ra'] = objects[[f'{b}_ra' for b in ['u', 'g', 'r', 'i']]].mean(axis=1, skipna=True)\n",
    "objects['mean_dec'] = objects[[f'{b}_dec' for b in ['u', 'g', 'r', 'i']]].mean(axis=1, skipna=True)\n",
    "objects\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold object DataFrames\n",
    "diaobject_list = []\n",
    "\n",
    "# Loop over tracts via obj_refs\n",
    "for diaobj_ref in tqdm(diaobj_refs):\n",
    "    try:\n",
    "        # Load full object table for this tract\n",
    "        table = butler.get(\"dia_object\", dataId=diaobj_ref.dataId)\n",
    "        # table = butler.get(\"object\", dataId=obj_ref.dataId)\n",
    "        diaobject_list.append(table)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: objectTable_tract not found for tract {diaobject_list.dataId['tract']}. Skipping.\")\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "diaobjects = pd.concat(diaobject_list, ignore_index=False) if diaobject_list else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold object DataFrames\n",
    "diaobject_list_w19 = []\n",
    "\n",
    "# Loop over tracts via obj_refs\n",
    "for diaobj_ref in tqdm(diaobj_refs_w19):\n",
    "    try:\n",
    "        # Load full object table for this tract\n",
    "        table = butler_w19.get(\"dia_object\", dataId=diaobj_ref.dataId)\n",
    "        # table = butler.get(\"object\", dataId=obj_ref.dataId)\n",
    "        diaobject_list_w19.append(table)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: objectTable_tract not found for tract {diaobject_list.dataId['tract']}. Skipping.\")\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "diaobjects_w19 = pd.concat(diaobject_list_w19, ignore_index=False) if diaobject_list_w19 else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaobjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaobjects_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(diaobjects['ra'], diaobjects['dec'], s=1, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects_m49 = objects[objects['mean_ra'].between(180, 192) & objects['mean_dec'].between(1, 13)]\n",
    "diaobjects_m49 = diaobjects[diaobjects['ra'].between(180, 192) & diaobjects['dec'].between(1, 13)]\n",
    "diaobjects_m49_w19 = diaobjects_w19[diaobjects_w19['ra'].between(180, 192) & diaobjects_w19['dec'].between(1, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaobjects_m49 = diaobjects_m49.copy()\n",
    "diaobjects_m49['diaObjectId'] = diaobjects_m49.index\n",
    "\n",
    "diaobjects_m49_w19 = diaobjects_m49_w19.copy()\n",
    "diaobjects_m49_w19['diaObjectId'] = diaobjects_m49_w19.index\n",
    "\n",
    "df_m49['ra'] = df_m49['_RAJ2000']\n",
    "df_m49['dec'] = df_m49['_DEJ2000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e63784",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST = lsdb.crossmatch(df_m49[['ra', 'dec', 'PF','P1O']], diaobjects_m49[['ra', 'dec', 'diaObjectId']].reset_index(drop=True), radius_arcsec=0.10)\n",
    "RR_LSST_computed = RR_LSST.compute()\n",
    "\n",
    "RR_LSST_w19 = lsdb.crossmatch(df_m49, diaobjects_m49_w19[['ra', 'dec', 'diaObjectId']].reset_index(drop=True), radius_arcsec=0.10)\n",
    "RR_LSST_computed_w19 = RR_LSST_w19.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7908830",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed.parquet\")\n",
    "RR_LSST_computed_w19.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_w19.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b51f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 2.5), sharey=True)\n",
    "\n",
    "axes[0].hist(RR_LSST_computed['_dist_arcsec'], bins=30)\n",
    "axes[0].set_title('RR_LSST w18')\n",
    "axes[0].set_xlabel('Dist (arcsec)')\n",
    "\n",
    "axes[1].hist(RR_LSST_computed_w19['_dist_arcsec'], bins=30)\n",
    "axes[1].set_title('RR_LSST w19')\n",
    "axes[1].set_xlabel('Dist (arcsec)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34037a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a bit silly because I have tract patch information in the object table\n",
    "\n",
    "# Get the skymap once\n",
    "skymap = butler.get(\"skyMap\", skymap=\"lsst_cells_v1\")\n",
    "\n",
    "# Prepare storage for tract and patch values\n",
    "tracts = []\n",
    "patches = []\n",
    "\n",
    "# Loop through the table and compute tract/patch for each coordinate\n",
    "for ra, dec in zip(RR_LSST_computed[\"ra_left\"], RR_LSST_computed[\"dec_left\"]):\n",
    "    radec = geom.SpherePoint(ra, dec, geom.degrees)\n",
    "    tractInfo = skymap.findTract(radec)\n",
    "    patchInfo = tractInfo.findPatch(radec)\n",
    "    \n",
    "    tr_id = tractInfo.getId()\n",
    "    pt_idx = patchInfo.getIndex()  # tuple like (x, y)\n",
    "    \n",
    "    tracts.append(tr_id)\n",
    "    patches.append(f\"{pt_idx[0]},{pt_idx[1]}\")  # optional: convert to string for easier saving/plotting\n",
    "\n",
    "# Add as new columns to the original DataFrame\n",
    "RR_LSST_computed[\"tract\"] = tracts\n",
    "RR_LSST_computed[\"patch\"] = patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a bit silly because I have tract patch information in the object table\n",
    "\n",
    "# Get the skymap once\n",
    "skymap = butler.get(\"skyMap\", skymap=\"lsst_cells_v1\")\n",
    "\n",
    "# Prepare storage for tract and patch values\n",
    "tracts = []\n",
    "patches = []\n",
    "\n",
    "# Loop through the table and compute tract/patch for each coordinate\n",
    "for ra, dec in zip(RR_LSST_computed_w19[\"ra_left\"], RR_LSST_computed_w19[\"dec_left\"]):\n",
    "    radec = geom.SpherePoint(ra, dec, geom.degrees)\n",
    "    tractInfo = skymap.findTract(radec)\n",
    "    patchInfo = tractInfo.findPatch(radec)\n",
    "    \n",
    "    tr_id = tractInfo.getId()\n",
    "    pt_idx = patchInfo.getIndex()  # tuple like (x, y)\n",
    "    \n",
    "    tracts.append(tr_id)\n",
    "    patches.append(f\"{pt_idx[0]},{pt_idx[1]}\")  # optional: convert to string for easier saving/plotting\n",
    "\n",
    "# Add as new columns to the original DataFrame\n",
    "RR_LSST_computed_w19[\"tract\"] = tracts\n",
    "RR_LSST_computed_w19[\"patch\"] = patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of unique tract values\n",
    "RR_LSST_computed['tract'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_w19['tract'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4468f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d88ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_ids = RR_LSST_computed['tract'].unique()\n",
    "tract_list_str = \", \".join(str(t) for t in tract_ids)\n",
    "\n",
    "forcedSource_refs = butler.query_datasets(\n",
    "    \"dia_object_forced_source\",\n",
    "    where=f\"tract IN ({tract_list_str}) AND skymap='lsst_cells_v1'\"\n",
    ")\n",
    "\n",
    "print(len(forcedSource_refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_ids = RR_LSST_computed_w19['tract'].unique()\n",
    "tract_list_str = \", \".join(str(t) for t in tract_ids)\n",
    "\n",
    "forcedSource_refs_w19 = butler_w19.query_datasets(\n",
    "    \"dia_object_forced_source\",\n",
    "    where=f\"tract IN ({tract_list_str}) AND skymap='lsst_cells_v1'\"\n",
    ")\n",
    "\n",
    "print(len(forcedSource_refs_w19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun this cell with the new data and butler \n",
    "\"\"\"\n",
    "# Step 1: Prepare your list of target objectIds\n",
    "target_objectIds = set(RR_LSST_computed['diaObjectId_right'].values)\n",
    "\n",
    "# Step 3: Loop through datasets and filter by objectId\n",
    "matched_forced_sources = []\n",
    "\n",
    "for ref in tqdm(forcedSource_refs):\n",
    "    try:\n",
    "        table = butler.get(ref)  # Astropy table\n",
    "        df = table.to_pandas()\n",
    "\n",
    "        # Filter only the objectIds you're interested in\n",
    "        df_filtered = df[df[\"diaObjectId\"].isin(target_objectIds)]\n",
    "        if not df_filtered.empty:\n",
    "            matched_forced_sources.append(df_filtered)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to load {ref.dataId} — {e}\")\n",
    "\n",
    "# Step 4: Combine all matched rows into one DataFrame\n",
    "if matched_forced_sources:\n",
    "    all_forced_sources = pd.concat(matched_forced_sources, ignore_index=True)\n",
    "    print(f\"Retrieved {len(all_forced_sources)} forced source rows for {len(target_objectIds)} objectIds.\")\n",
    "else:\n",
    "    all_forced_sources = pd.DataFrame()\n",
    "    print(\"No forced sources found.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734235b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Step 1: Prepare your list of target objectIds\n",
    "target_objectIds = set(RR_LSST_computed_w19['diaObjectId_right'].values)\n",
    "\n",
    "# Step 3: Loop through datasets and filter by objectId\n",
    "matched_forced_sources = []\n",
    "\n",
    "for ref in tqdm(forcedSource_refs_w19):\n",
    "    try:\n",
    "        table = butler_w19.get(ref)  # Astropy table\n",
    "        df = table.to_pandas()\n",
    "\n",
    "        # Filter only the objectIds you're interested in\n",
    "        df_filtered = df[df[\"diaObjectId\"].isin(target_objectIds)]\n",
    "        if not df_filtered.empty:\n",
    "            matched_forced_sources.append(df_filtered)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to load {ref.dataId} — {e}\")\n",
    "\n",
    "# Step 4: Combine all matched rows into one DataFrame\n",
    "if matched_forced_sources:\n",
    "    all_forced_sources_w19 = pd.concat(matched_forced_sources, ignore_index=True)\n",
    "    print(f\"Retrieved {len(all_forced_sources)} forced source rows for {len(target_objectIds)} objectIds.\")\n",
    "else:\n",
    "    all_forced_sources_w19 = pd.DataFrame()\n",
    "    print(\"No forced sources found.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f061c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_forced_sources_w19.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/all_forced_sources_w19.parquet\")\n",
    "# all_forced_sources.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/all_forced_sources.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ba9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forced_sources = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/all_forced_sources.parquet\")\n",
    "all_forced_sources_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/all_forced_sources_w19.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a714bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_objectIds = all_forced_sources['diaObjectId'].unique()\n",
    "target_objectIds_w19 = all_forced_sources_w19['diaObjectId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add length of lightcurve to RR_LSST_computed \n",
    "\n",
    "# Step 1: Count number of forced source rows per objectId\n",
    "lc_lengths = (\n",
    "    all_forced_sources\n",
    "    .groupby(\"diaObjectId\")\n",
    "    .size()\n",
    "    .reset_index(name=\"lc_length\")  # column with the lightcurve length\n",
    ")\n",
    "\n",
    "# Step 2: Merge into RR_LSST_computed using objectId_right\n",
    "RR_LSST_computed_with_length = RR_LSST_computed.merge(\n",
    "    lc_lengths,\n",
    "    how='left',\n",
    "    left_on='diaObjectId_right',\n",
    "    right_on='diaObjectId'\n",
    ")\n",
    "\n",
    "# Optional: drop duplicate objectId column if desired\n",
    "RR_LSST_computed_with_length = RR_LSST_computed_with_length.drop(columns=[\"diaObjectId\"])\n",
    "\n",
    "\n",
    "# Step 1: Count number of forced source rows per objectId\n",
    "lc_lengths = (\n",
    "    all_forced_sources_w19\n",
    "    .groupby(\"diaObjectId\")\n",
    "    .size()\n",
    "    .reset_index(name=\"lc_length\")  # column with the lightcurve length\n",
    ")\n",
    "\n",
    "# Step 2: Merge into RR_LSST_computed using objectId_right\n",
    "RR_LSST_computed_with_length_w19 = RR_LSST_computed_w19.merge(\n",
    "    lc_lengths,\n",
    "    how='left',\n",
    "    left_on='diaObjectId_right',\n",
    "    right_on='diaObjectId'\n",
    ")\n",
    "\n",
    "# Optional: drop duplicate objectId column if desired\n",
    "RR_LSST_computed_with_length_w19 = RR_LSST_computed_with_length_w19.drop(columns=[\"diaObjectId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries that are empty or contain only whitespace\n",
    "mask = RR_LSST_computed_with_length['PF_left'].str.strip() != ''\n",
    "RR_LSST_computed_with_length = RR_LSST_computed_with_length[mask].copy()\n",
    "\n",
    "mask = RR_LSST_computed_with_length_w19['PF_left'].str.strip() != ''\n",
    "RR_LSST_computed_with_length_w19 = RR_LSST_computed_with_length_w19[mask].copy()\n",
    "\n",
    "# Optionally convert 'PF_left' to float\n",
    "RR_LSST_computed_with_length['PF_left'] = RR_LSST_computed_with_length['PF_left'].astype(float)\n",
    "RR_LSST_computed_with_length_w19['PF_left'] = RR_LSST_computed_with_length_w19['PF_left'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long = RR_LSST_computed_with_length[(RR_LSST_computed_with_length['lc_length']>120) ]\n",
    "RR_LSST_computed_long_w19 = RR_LSST_computed_with_length_w19[(RR_LSST_computed_with_length_w19['lc_length']>120) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac285e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long_w19.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of good RR Lyrae\n",
    "RR_LSST_computed_long.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_long.parquet\")\n",
    "RR_LSST_computed_long_w19.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_long_w19.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long= pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_long.parquet\")\n",
    "RR_LSST_computed_long_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_long_w19.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60eb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Show up to 42 rows in notebook or terminal\n",
    "pd.set_option(\"display.max_rows\", 42)\n",
    "\n",
    "# Now display the DataFrame\n",
    "RR_LSST_computed_long_w19[[\"Source_left\", \"diaObjectId_right\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_longest = int(RR_LSST_computed_long[RR_LSST_computed_long['lc_length'] == np.max(RR_LSST_computed_long['lc_length'])]['diaObjectId_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a lightcurve\n",
    "single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == obj_id_longest]\n",
    "single_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_ids = all_forced_sources['visit'].unique()\n",
    "np.save(\"/sdf/home/n/ncaplar/rrlyrae_lightcurves/visit_ids.npy\", visit_ids)\n",
    "\n",
    "visit_ids_w19 = all_forced_sources_w19['visit'].unique()\n",
    "np.save(\"/sdf/home/n/ncaplar/rrlyrae_lightcurves/visit_ids_w19.npy\", visit_ids_w19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c54a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.load('/sdf/home/n/ncaplar/rrlyrae_lightcurves/times.npy')\n",
    "times_w19 = np.load('/sdf/home/n/ncaplar/rrlyrae_lightcurves/times_w19.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_visits_df = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/filtered_visits_df.parquet\")\n",
    "filtered_visits_df_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/filtered_visits_df_w19.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_visits_df['visit_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_visits_df_w19['visit_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d79737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check that the length matches\n",
    "assert len(visit_ids) == len(times), \"Mismatch in number of visits and MJD times\"\n",
    "assert len(visit_ids_w19) == len(times_w19), \"Mismatch in number of visits and MJD times\"\n",
    "\n",
    "# Step 3: Create a mapping dictionary\n",
    "visit_to_mjd = dict(zip(filtered_visits_df['visit_id'], filtered_visits_df['exp_midpt_mjd']))\n",
    "visit_to_mjd_w19 = dict(zip(filtered_visits_df_w19['visit_id'], filtered_visits_df_w19['exp_midpt_mjd']))\n",
    "\n",
    "# Step 4: Map the MJD to the all_forced_sources DataFrame\n",
    "all_forced_sources['mjd'] = all_forced_sources['visit'].map(visit_to_mjd)\n",
    "all_forced_sources_w19['mjd'] = all_forced_sources_w19['visit'].map(visit_to_mjd_w19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id = RR_LSST_computed_long['diaObjectId_right'].unique()[11]\n",
    "single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == object_id].copy()\n",
    "single_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6778c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_w19 = RR_LSST_computed_long_w19['diaObjectId_right'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of rows per diaObjectId\n",
    "lightcurve_lengths = all_forced_sources_w19.groupby('diaObjectId').size()\n",
    "\n",
    "# Get top 30 diaObjectIds with longest lightcurves\n",
    "top_30_ids = lightcurve_lengths.nlargest(50).index\n",
    "\n",
    "# If you want the actual DataFrame entries for these top 30\n",
    "top_30_lcs = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'].isin(top_30_ids)]\n",
    "top_30_lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a36c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both are numpy arrays\n",
    "id_w19_array = np.array(id_w19)\n",
    "top_30_ids_array = top_30_lcs['diaObjectId'].unique()\n",
    "\n",
    "# Compute intersection\n",
    "intersect_ids_w19 = np.intersect1d(id_w19_array, top_30_ids_array)\n",
    "print(len(intersect_ids_w19), \"common IDs found in both lists.\")\n",
    "intersect_ids_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(single_lc['mjd'], single_lc['psfFluxErr'], s=1, label='w18', alpha=0.5)\n",
    "# plt.scatter(single_lc_w19['mjd'], single_lc_w19['psfFluxErr'], s=1, label='w19', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d64d81",
   "metadata": {},
   "source": [
    "# W18 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_index =  np.array([70927777120911428, 72591613091643579, 74238475351621650, 72584053949202434, 74241224130691123, 74242667239702535, 74249126870515736, 74244522665574412,  75894133704622083, 75895508094156806 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeea3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == 74241224130691123].copy()\n",
    "\n",
    "# Identify all columns that contain 'flag'\n",
    "flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "\n",
    "# Exclude rows where any flag column is True\n",
    "flag_mask = ~(single_lc[flag_cols].any(axis=1))  # True where all flags are False\n",
    "single_lc = single_lc[flag_mask]\n",
    "single_lc[flag_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w18\n",
    "\n",
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\"\n",
    "}\n",
    "# Sinusoid model: phase in [0, 1]\n",
    "def sinusoid(phase, A, phi0, mean_mag):\n",
    "    return mean_mag + A * np.sin(2 * np.pi * phase + phi0)\n",
    "\n",
    "# Convert flux to magnitude\n",
    "def create_mag(sciFlux):\n",
    "    return u.nJy.to(u.ABmag, sciFlux)\n",
    "# for object_id in RR_LSST_computed_long['diaObjectId_right'].unique():\n",
    "for object_id in good_index:\n",
    "    # Get one object's lightcurve and period\n",
    "    #object_id = RR_LSST_computed_long['objectId_right'].values[7]\n",
    "    single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == object_id].copy()\n",
    "    \n",
    "    # Identify all columns that contain 'flag'\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "\n",
    "    # Exclude rows where any flag column is True\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))  # True where all flags are False\n",
    "    single_lc = single_lc[flag_mask]\n",
    "    \n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "    single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]\n",
    "    #single_lc_with_columns.to_parquet(\n",
    "    #    \"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/test/w_18_objectId_\"\n",
    "    #    + str(int(single_lc_with_columns['diaObjectId'].values[0])) + \".parquet\"\n",
    "    #)    \n",
    "    \n",
    "    period = float(RR_LSST_computed_long[RR_LSST_computed_long['diaObjectId_right'] == int(object_id)]['PF_left'].values[0])\n",
    "    if pd.isna(period):\n",
    "        print(f\"No period for object {object_id}\")\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "        global_ymin = np.inf\n",
    "        global_ymax = -np.inf\n",
    "\n",
    "\n",
    "\n",
    "        for band, group in single_lc.groupby(\"band\"):\n",
    "            time = group[\"mjd\"].values.astype(float)\n",
    "            visit = group[\"visit\"].values.astype(int)\n",
    "            flux = group[\"psfFlux\"].values.astype(float)\n",
    "            flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "\n",
    "            mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "            # Save the lightcurve (including computed mags and errors)\n",
    "\n",
    "            \n",
    "            phase = (time % period) / period\n",
    "            valid = np.isfinite(mag) & np.isfinite(phase) & np.isfinite(mag_err)\n",
    "\n",
    "            # Save the lightcurve (including computed mags and errors)\n",
    "            lc_df = pd.DataFrame({\n",
    "                \"diaobjectId\": object_id,\n",
    "                \"band\": band,\n",
    "                \"visit\": visit,\n",
    "                \"mjd\": time,\n",
    "                \"psfFlux\": flux,\n",
    "                \"psfFluxErr\": flux_err,\n",
    "                \"mag\": mag,\n",
    "                \"magErr\": mag_err,\n",
    "                \"phase\": phase\n",
    "            })[valid]  # only keep valid rows\n",
    "\n",
    "            lightcurve_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/test/w_18_objectId_lightcurve_{int(object_id)}_{band}.parquet\"\n",
    "            lc_df.to_parquet(lightcurve_path, index=False)\n",
    "            # Fit sinusoid model\n",
    "            try:\n",
    "                popt, _ = curve_fit(\n",
    "                    sinusoid, phase[valid], mag[valid],\n",
    "                    p0=[0.1, 0.0, np.nanmean(mag)],\n",
    "                    sigma=mag_err[valid],\n",
    "                    absolute_sigma=True\n",
    "                )\n",
    "                A_fit, phi0_fit, mean_mag_fit = popt\n",
    "                # Save fit parameters to Parquet\n",
    "                fit_df = pd.DataFrame({\n",
    "                    \"objectId\": [object_id],\n",
    "                    \"band\": [band],\n",
    "                    \"period\": [period],\n",
    "                    \"A\": [A_fit],\n",
    "                    \"phi0\": [phi0_fit],\n",
    "                    \"mean_mag\": [mean_mag_fit]\n",
    "                })\n",
    "                parquet_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/test/w_18_objectId_popt_{int(object_id)}_{band}.parquet\"\n",
    "                fit_df.to_parquet(parquet_path, index=False)\n",
    "                \n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Fit failed for band {band}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Model values\n",
    "            phase_model = np.linspace(0, 1, 500)\n",
    "            mag_model_phase = sinusoid(phase_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "            t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "            phase_t_model = (t_model % period) / period\n",
    "            mag_model_time = sinusoid(phase_t_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "            # Update global min/max for zoomed y-axis\n",
    "            combined_mags = np.concatenate([mag[valid], mag_model_phase, mag_model_time])\n",
    "            global_ymin = min(global_ymin, np.nanmin(combined_mags))\n",
    "            #global_ymean = np.mean(global_ymean, np.nanmin(combined_mags))\n",
    "            global_ymax = max(global_ymax, np.nanmax(combined_mags))\n",
    "\n",
    "            # Plot: time-domain\n",
    "            axes[0].errorbar(time, mag, yerr=mag_err, fmt='o', label=f\"{band}-band\",\n",
    "                            alpha=0.6, color=band_colors.get(band, 'gray'), capsize=3)\n",
    "            axes[0].plot(t_model, mag_model_time, '--',\n",
    "                        label=f\"Fit ({band})\", color=band_colors.get(band, 'gray'))\n",
    "\n",
    "            # Plot: phase-folded\n",
    "            axes[1].errorbar(phase, mag, yerr=mag_err, fmt='o', label=f\"{band}-band\",\n",
    "                            alpha=0.6, color=band_colors.get(band, 'gray'), capsize=3)\n",
    "            axes[1].plot(phase_model, mag_model_phase, '--',\n",
    "                        label=f\"Fit ({band})\", color=band_colors.get(band, 'gray'))\n",
    "\n",
    "        # Final plot adjustments\n",
    "        for ax in axes:\n",
    "            ax.invert_yaxis()\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            ax.set_ylabel(\"Magnitude\")\n",
    "\n",
    "        axes[0].set_xlabel(\"MJD\")\n",
    "        axes[0].set_title(\"Time Domain\")\n",
    "\n",
    "        axes[1].set_xlabel(\"Phase\")\n",
    "        axes[1].set_xlim(0, 1)\n",
    "        axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "        # Apply padded y-limits\n",
    "        pad = 0.1 * (global_ymax - global_ymin)\n",
    "        axes[0].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "        axes[1].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "\n",
    "        plt.suptitle(f\"Object ID {object_id} / Period = {period:.4f} days\")\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.88)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef95b0",
   "metadata": {},
   "source": [
    "# W19 original fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_long_w19.parquet\")\n",
    "all_forced_sources_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/all_forced_sources_w19.parquet\")\n",
    "visit_ids_w19 = all_forced_sources_w19['visit'].unique()\n",
    "times_w19 = np.load('/sdf/home/n/ncaplar/rrlyrae_lightcurves/times_w19.npy')\n",
    "filtered_visits_df_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/filtered_visits_df_w19.parquet\")\n",
    "visit_to_mjd_w19 = dict(zip(filtered_visits_df_w19['visit_id'], filtered_visits_df_w19['exp_midpt_mjd']))\n",
    "all_forced_sources_w19['mjd'] = all_forced_sources_w19['visit'].map(visit_to_mjd_w19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40cd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_ids_w19 = np.array([69261123651633168, 70922760599109657, 70922898038063320,\n",
    "       70927777120911374, 70930113583120389, 70934168032247856,\n",
    "       72578144074203143, 72582679559667755, 72584053949202435,\n",
    "       72584191388155907, 72585222180306950, 72585771936120856,\n",
    "       72586871447748649, 72591613091643426, 72597866564026416,\n",
    "       72598553758793772, 72601233818386462, 74238475351621651,\n",
    "       74239231265865808, 74240536935923747, 74241224130691109,\n",
    "       74241636447551510, 74242667239702537, 74243423153946646,\n",
    "       74244522665574414, 74246446810923009, 74247477603074095,\n",
    "       74247615042027587, 74249126870515732, 74249195589992487,\n",
    "       74252562844352545, 74255242903945239, 74256479854526548,\n",
    "       74257304488247305, 74258060402491403, 75889735658111016,\n",
    "       75894133704622084, 75895508094156808, 75896813764214861,\n",
    "       75897019922645015, 75897294800551970, 75897638397935633])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68fd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4711b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w19\n",
    "good_index_w19 =  np.array([70927777120911374, 72585222180306950, 74238475351621651, \n",
    "   74241636447551510, 74242667239702537, 74246446810923009, 74249126870515732, \n",
    "   75894133704622084, 75895508094156808, 75897638397935633])\n",
    "\n",
    "# good_index_w19 = intersect_ids_w19\n",
    "\n",
    "# Define band color mapping\n",
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\",\n",
    "    \"z\": \"purple\",\n",
    "    \"y\": \"black\"\n",
    "}\n",
    "\n",
    "# Sinusoid model\n",
    "def sinusoid(phase, A, phi0, mean_mag):\n",
    "    return mean_mag + A * np.sin(2 * np.pi * phase + phi0)\n",
    "\n",
    "# Convert flux to magnitude\n",
    "def create_mag(flux):\n",
    "    return u.nJy.to(u.ABmag, flux)\n",
    "\n",
    "# Iterate over selected objects\n",
    "for object_id in good_index_w19:\n",
    "    single_lc = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'] == object_id].copy()\n",
    "\n",
    "    # Identify and apply flag mask\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))\n",
    "    single_lc = single_lc[flag_mask]\n",
    "\n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "    single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]\n",
    "    single_lc_with_columns.to_parquet(\n",
    "        \"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/w_19_objectId_\"\n",
    "        + str(int(single_lc_with_columns['diaObjectId'].values[0])) + \".parquet\"\n",
    "    )  \n",
    "    # Period\n",
    "    period = float(\n",
    "        RR_LSST_computed_long_w19[\n",
    "            RR_LSST_computed_long_w19['diaObjectId_right'] == int(object_id)\n",
    "        ]['PF_left'].values[0]\n",
    "    )\n",
    "    \n",
    "    if pd.isna(period):\n",
    "        print(f\"No period for object {object_id}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        time = group[\"mjd\"].values.astype(float)\n",
    "        visit = group[\"visit\"].values.astype(int)\n",
    "        flux = group[\"psfFlux\"].values.astype(float)\n",
    "        flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "\n",
    "        mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "        phase = (time % period) / period\n",
    "\n",
    "        valid = np.isfinite(mag) & np.isfinite(phase) & np.isfinite(mag_err)\n",
    "\n",
    "        # Save LC with computed columns\n",
    "        lc_df = pd.DataFrame({\n",
    "            \"diaObjectId\": object_id,\n",
    "            \"band\": band,\n",
    "            \"visit\": visit,\n",
    "            \"mjd\": time,\n",
    "            \"psfFlux\": flux,\n",
    "            \"psfFluxErr\": flux_err,\n",
    "            \"mag\": mag,\n",
    "            \"magErr\": mag_err,\n",
    "            \"phase\": phase\n",
    "        })[valid]\n",
    "        \n",
    "        lightcurve_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/w_19_objectId_lightcurve_{int(object_id)}_{band}.parquet\"\n",
    "        lc_df.to_parquet(lightcurve_path, index=False)\n",
    "        # Fit sinusoid\n",
    "        try:\n",
    "            popt, _ = curve_fit(\n",
    "                sinusoid, phase[valid], mag[valid],\n",
    "                p0=[0.1, 0.0, np.nanmean(mag)],\n",
    "                sigma=mag_err[valid],\n",
    "                absolute_sigma=True\n",
    "            )\n",
    "            A_fit, phi0_fit, mean_mag_fit = popt\n",
    "            # Save fit parameters to Parquet\n",
    "            fit_df = pd.DataFrame({\n",
    "                \"objectId\": [object_id],\n",
    "                \"band\": [band],\n",
    "                \"period\": [period],\n",
    "                \"A\": [A_fit],\n",
    "                \"phi0\": [phi0_fit],\n",
    "                \"mean_mag\": [mean_mag_fit]\n",
    "            })\n",
    "            parquet_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/w_19_objectId_popt_{int(object_id)}_{band}.parquet\"\n",
    "            fit_df.to_parquet(parquet_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Fit failed for band {band}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Model curves\n",
    "        phase_model = np.linspace(0, 1, 500)\n",
    "        mag_model_phase = sinusoid(phase_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "        t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "        phase_t_model = (t_model % period) / period\n",
    "        mag_model_time = sinusoid(phase_t_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "        # Update global y-limits\n",
    "        combined_mags = np.concatenate([mag[valid], mag_model_phase, mag_model_time])\n",
    "        global_ymin = min(global_ymin, np.nanmin(combined_mags))\n",
    "        global_ymax = max(global_ymax, np.nanmax(combined_mags))\n",
    "\n",
    "        # Plot: time-domain\n",
    "        axes[0].errorbar(\n",
    "            time, mag, yerr=mag_err, fmt='o', alpha=0.6,\n",
    "            label=f\"{band}-band\", color=band_colors.get(band, 'gray'), capsize=3\n",
    "        )\n",
    "        axes[0].plot(\n",
    "            t_model, mag_model_time, '--',\n",
    "            label=f\"Fit ({band})\", color=band_colors.get(band, 'gray')\n",
    "        )\n",
    "\n",
    "        # Plot: phase-folded\n",
    "        axes[1].errorbar(\n",
    "            phase, mag, yerr=mag_err, fmt='o', alpha=0.6,\n",
    "            color=band_colors.get(band, 'gray'), capsize=3\n",
    "        )\n",
    "        axes[1].plot(\n",
    "            phase_model, mag_model_phase, '--',\n",
    "            color=band_colors.get(band, 'gray')\n",
    "        )\n",
    "\n",
    "    # Final plot adjustments\n",
    "    for ax in axes:\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylabel(\"Magnitude\")\n",
    "\n",
    "    axes[0].legend()\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    pad = 0.1 * (global_ymax - global_ymin)\n",
    "    axes[0].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "    axes[1].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "\n",
    "    plt.suptitle(f\"Object ID {object_id} / Period = {period:.4f} days\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_ids_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([70927777120911374, 72585222180306950, 74238475351621651, \n",
    "#    74241636447551510, 74242667239702537, 74246446810923009, 74249126870515732, \n",
    "#    75894133704622084, 75895508094156808, 75897638397935633])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([70922760599109657, 70934168032247856, 72598553758793772, 74238475351621651, 74239231265865808, 74246446810923009, 74258060402491403])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b27198",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long_w19[RR_LSST_computed_long_w19['diaObjectId_right'] == int(70922760599109657)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy import units as u\n",
    "\n",
    "# Define color per band\n",
    "band_colors = {\n",
    "    \"u\": \"blue\", \"g\": \"green\", \"r\": \"red\",\n",
    "    \"i\": \"brown\", \"z\": \"purple\", \"y\": \"black\"\n",
    "}\n",
    "\n",
    "# Fourier model with N harmonics\n",
    "def fourier_model(phase, *params):\n",
    "    N = (len(params) - 1) // 2\n",
    "    result = params[0]\n",
    "    for k in range(1, N + 1):\n",
    "        Ak = params[2 * k - 1]\n",
    "        phik = params[2 * k]\n",
    "        result += Ak * np.cos(2 * np.pi * k * phase + phik)\n",
    "    return result\n",
    "\n",
    "# Convert flux to magnitude\n",
    "def create_mag(flux):\n",
    "    return u.nJy.to(u.ABmag, flux)\n",
    "\n",
    "# Parameters\n",
    "N_harmonics = 4\n",
    "good_index_w19 = np.array([70922760599109657, 72585771936120856, 72598553758793772, 74238475351621651, 74239231265865808, 74246446810923009, 74258060402491403])\n",
    "\n",
    "for object_id in good_index_w19:\n",
    "    single_lc = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'] == object_id].copy()\n",
    "\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))\n",
    "    single_lc = single_lc[flag_mask]\n",
    "\n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "    single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', \n",
    "                                        'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', \n",
    "                                        'mjd', 'psfFlux', 'psfMag', 'band']]\n",
    "    \n",
    "    single_lc_with_columns.to_parquet(\n",
    "        f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/Fourier/w_19_objectId_{int(object_id)}.parquet\"\n",
    "    )\n",
    "\n",
    "    period = float(\n",
    "        RR_LSST_computed_long_w19[\n",
    "            RR_LSST_computed_long_w19['diaObjectId_right'] == int(object_id)\n",
    "        ]['PF_left'].values[0]\n",
    "    )\n",
    "    \n",
    "    if pd.isna(period):\n",
    "        print(f\"No period for object {object_id}\")\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        time = group[\"mjd\"].values.astype(float)\n",
    "        visit = group[\"visit\"].values.astype(int)\n",
    "        flux = group[\"psfFlux\"].values.astype(float)\n",
    "        flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "\n",
    "        mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "        phase = (time % period) / period\n",
    "\n",
    "        valid = np.isfinite(mag) & np.isfinite(phase) & np.isfinite(mag_err)\n",
    "\n",
    "        lc_df = pd.DataFrame({\n",
    "            \"diaObjectId\": object_id,\n",
    "            \"band\": band,\n",
    "            \"visit\": visit,\n",
    "            \"mjd\": time,\n",
    "            \"psfFlux\": flux,\n",
    "            \"psfFluxErr\": flux_err,\n",
    "            \"mag\": mag,\n",
    "            \"magErr\": mag_err,\n",
    "            \"phase\": phase\n",
    "        })[valid]\n",
    "        lightcurve_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/Fourier/w_19_objectId_lightcurve_{int(object_id)}_{band}.parquet\"\n",
    "        lc_df.to_parquet(lightcurve_path, index=False)\n",
    "        try:\n",
    "            mag_mean = np.nanmean(mag[valid])\n",
    "            p0 = [mag_mean] + [0.1, 0.0] * N_harmonics\n",
    "\n",
    "            popt, _ = curve_fit(\n",
    "                fourier_model, phase[valid], mag[valid],\n",
    "                p0=p0,\n",
    "                sigma=mag_err[valid],\n",
    "                absolute_sigma=True,\n",
    "                maxfev=10000\n",
    "            )\n",
    "\n",
    "            # Save fit parameters (optional)\n",
    "            fit_df = pd.DataFrame({\n",
    "                \"objectId\": [object_id],\n",
    "                \"band\": [band],\n",
    "                \"period\": [period],\n",
    "                \"mean_mag\": [popt[0]],\n",
    "                **{f\"A{k}\": [popt[2*k - 1]] for k in range(1, N_harmonics + 1)},\n",
    "                **{f\"phi{k}\": [popt[2*k]] for k in range(1, N_harmonics + 1)},\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fourier fit failed for object {object_id} in band {band}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Evaluate model\n",
    "        phase_model = np.linspace(0, 1, 500)\n",
    "        mag_model_phase = fourier_model(phase_model, *popt)\n",
    "\n",
    "        t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "        phase_t_model = (t_model % period) / period\n",
    "        mag_model_time = fourier_model(phase_t_model, *popt)\n",
    "\n",
    "        # Update y-limits\n",
    "        combined_mags = np.concatenate([mag[valid], mag_model_phase, mag_model_time])\n",
    "        global_ymin = min(global_ymin, np.nanmin(combined_mags))\n",
    "        global_ymax = max(global_ymax, np.nanmax(combined_mags))\n",
    "\n",
    "        # Plot time-domain\n",
    "        axes[0].errorbar(\n",
    "            time, mag, yerr=mag_err, fmt='o', alpha=0.6,\n",
    "            label=f\"{band}-band\", color=band_colors.get(band, 'gray'), capsize=3\n",
    "        )\n",
    "        axes[0].plot(\n",
    "            t_model, mag_model_time, '--',\n",
    "            label=f\"Fourier fit ({band})\", color=band_colors.get(band, 'gray')\n",
    "        )\n",
    "\n",
    "        # Plot phase-folded\n",
    "        axes[1].errorbar(\n",
    "            phase, mag, yerr=mag_err, fmt='o', alpha=0.6,\n",
    "            color=band_colors.get(band, 'gray'), capsize=3\n",
    "        )\n",
    "        axes[1].plot(\n",
    "            phase_model, mag_model_phase, '--',\n",
    "            color=band_colors.get(band, 'gray')\n",
    "        )\n",
    "\n",
    "    # Final plot tweaks\n",
    "    for ax in axes:\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylabel(\"Magnitude\")\n",
    "\n",
    "    axes[0].legend()\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    pad = 0.1 * (global_ymax - global_ymin)\n",
    "    axes[0].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "    axes[1].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "\n",
    "    plt.suptitle(f\"Object ID {object_id} / Period = {period:.4f} days\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4d5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c68ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61d29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8516bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa3b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc4ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e44f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8170547",
   "metadata": {},
   "source": [
    "# Sinus fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux = single_lc['psfFlux'].values.astype(float)\n",
    "flux_err = single_lc['psfFluxErr'].values.astype(float)\n",
    "\n",
    "mag, mag_err = create_mag_errors(flux, flux_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba06138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w19\n",
    "good_index_w19 =  np.array([70927777120911374, 72585222180306950, 74238475351621651, \n",
    "    74241636447551510, 74242667239702537, 74246446810923009, 74249126870515732, \n",
    "    75894133704622084, 75895508094156808, 75897638397935633])\n",
    "# Define band color mapping\n",
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\",\n",
    "    \"z\": \"purple\",\n",
    "    \"y\": \"black\"\n",
    "}\n",
    "\n",
    "# Sinusoid model\n",
    "def sinusoid(phase, A, phi0, mean_mag):\n",
    "    return mean_mag + A * np.sin(2 * np.pi * phase + phi0)\n",
    "\n",
    "# Convert flux to magnitude\n",
    "def create_mag(flux):\n",
    "    return u.nJy.to(u.ABmag, flux)\n",
    "\n",
    "# Iterate over selected objects\n",
    "for object_id in intersect_ids:\n",
    "    single_lc = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'] == object_id].copy()\n",
    "\n",
    "    # Identify and apply flag mask\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))\n",
    "    single_lc = single_lc[flag_mask]\n",
    "\n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "    single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]\n",
    "    single_lc_with_columns.to_parquet(\n",
    "        \"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/w_19_objectId_\"\n",
    "        + str(int(single_lc_with_columns['diaObjectId'].values[0])) + \".parquet\"\n",
    "    )  \n",
    "    # Period\n",
    "    period = float(\n",
    "        RR_LSST_computed_long_w19[\n",
    "            RR_LSST_computed_long_w19['diaObjectId_right'] == int(object_id)\n",
    "        ]['PF_left'].values[0]\n",
    "    )\n",
    "    \n",
    "    if pd.isna(period):\n",
    "        print(f\"No period for object {object_id}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        time = group[\"mjd\"].values.astype(float)\n",
    "        visit = group[\"visit\"].values.astype(int)\n",
    "        flux = group[\"psfFlux\"].values.astype(float)\n",
    "        flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "\n",
    "        mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "        phase = (time % period) / period\n",
    "\n",
    "        valid = np.isfinite(mag) & np.isfinite(phase) & np.isfinite(mag_err)\n",
    "\n",
    "        # Save LC with computed columns\n",
    "        lc_df = pd.DataFrame({\n",
    "            \"diaObjectId\": object_id,\n",
    "            \"band\": band,\n",
    "            \"visit\": visit,\n",
    "            \"mjd\": time,\n",
    "            \"psfFlux\": flux,\n",
    "            \"psfFluxErr\": flux_err,\n",
    "            \"mag\": mag,\n",
    "            \"magErr\": mag_err,\n",
    "            \"phase\": phase\n",
    "        })[valid]\n",
    "        \n",
    "        lightcurve_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/w_19_objectId_lightcurve_{int(object_id)}_{band}.parquet\"\n",
    "        lc_df.to_parquet(lightcurve_path, index=False)\n",
    "        # Fit sinusoid\n",
    "        try:\n",
    "            popt, _ = curve_fit(\n",
    "                sinusoid, phase[valid], mag[valid],\n",
    "                p0=[0.1, 0.0, np.nanmean(mag)],\n",
    "                sigma=mag_err[valid],\n",
    "                absolute_sigma=True\n",
    "            )\n",
    "            A_fit, phi0_fit, mean_mag_fit = popt\n",
    "            # Save fit parameters to Parquet\n",
    "            fit_df = pd.DataFrame({\n",
    "                \"objectId\": [object_id],\n",
    "                \"band\": [band],\n",
    "                \"period\": [period],\n",
    "                \"A\": [A_fit],\n",
    "                \"phi0\": [phi0_fit],\n",
    "                \"mean_mag\": [mean_mag_fit]\n",
    "            })\n",
    "            parquet_path = f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/w_19_objectId_popt_{int(object_id)}_{band}.parquet\"\n",
    "            fit_df.to_parquet(parquet_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Fit failed for band {band}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Model curves\n",
    "        phase_model = np.linspace(0, 1, 500)\n",
    "        mag_model_phase = sinusoid(phase_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "        t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "        phase_t_model = (t_model % period) / period\n",
    "        mag_model_time = sinusoid(phase_t_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "        # Update global y-limits\n",
    "        combined_mags = np.concatenate([mag[valid], mag_model_phase, mag_model_time])\n",
    "        global_ymin = min(global_ymin, np.nanmin(combined_mags))\n",
    "        global_ymax = max(global_ymax, np.nanmax(combined_mags))\n",
    "\n",
    "        # Plot: time-domain\n",
    "        axes[0].errorbar(\n",
    "            time, mag, yerr=mag_err, fmt='o', alpha=0.6,\n",
    "            label=f\"{band}-band\", color=band_colors.get(band, 'gray'), capsize=3\n",
    "        )\n",
    "        axes[0].plot(\n",
    "            t_model, mag_model_time, '--',\n",
    "            label=f\"Fit ({band})\", color=band_colors.get(band, 'gray')\n",
    "        )\n",
    "\n",
    "        # Plot: phase-folded\n",
    "        axes[1].errorbar(\n",
    "            phase, mag, yerr=mag_err, fmt='o', alpha=0.6,\n",
    "            color=band_colors.get(band, 'gray'), capsize=3\n",
    "        )\n",
    "        axes[1].plot(\n",
    "            phase_model, mag_model_phase, '--',\n",
    "            color=band_colors.get(band, 'gray')\n",
    "        )\n",
    "\n",
    "    # Final plot adjustments\n",
    "    for ax in axes:\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylabel(\"Magnitude\")\n",
    "\n",
    "    axes[0].legend()\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    pad = 0.1 * (global_ymax - global_ymin)\n",
    "    axes[0].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "    axes[1].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "\n",
    "    plt.suptitle(f\"Object ID {object_id} / Period = {period:.4f} days\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d5b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a47cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bab77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing loading\n",
    "\n",
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\"\n",
    "}\n",
    "\n",
    "def sinusoid(phase, A, phi0, mean_mag):\n",
    "    return mean_mag + A * np.sin(2 * np.pi * phase + phi0)\n",
    "\n",
    "for object_id in good_index:\n",
    "    #base_path = \"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/test\"\n",
    "    \n",
    "    # Load main lightcurve table\n",
    "    # lc_path = f\"{base_path}/w_18_objectId_{int(object_id)}.parquet\"\n",
    "    # single_lc = pd.read_parquet(lc_path)\n",
    "    \n",
    "    # Apply flag filtering if needed\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    if flag_cols:\n",
    "        single_lc = single_lc[~single_lc[flag_cols].any(axis=1)]\n",
    "\n",
    "    period = None  # Initialize period\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        try:\n",
    "            # Load per-band lightcurve\n",
    "            lc_band_path = f\"{base_path}/w_18_objectId_lightcurve_{int(object_id)}_{band}.parquet\"\n",
    "            lc_df = pd.read_parquet(lc_band_path)\n",
    "\n",
    "            # Load fit parameters\n",
    "            fit_path = f\"{base_path}/w_18_objectId_popt_{int(object_id)}_{band}.parquet\"\n",
    "            fit_df = pd.read_parquet(fit_path)\n",
    "            A, phi0, mean_mag = fit_df.loc[0, ['A', 'phi0', 'mean_mag']]\n",
    "            period = fit_df.loc[0, 'period']\n",
    "\n",
    "            # Extract data\n",
    "            time = lc_df[\"mjd\"].values\n",
    "            mag = lc_df[\"mag\"].values\n",
    "            mag_err = lc_df[\"magErr\"].values\n",
    "            phase = lc_df[\"phase\"].values\n",
    "\n",
    "            # Model values\n",
    "            phase_model = np.linspace(0, 1, 500)\n",
    "            mag_model_phase = sinusoid(phase_model, A, phi0, mean_mag)\n",
    "\n",
    "            t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "            phase_t_model = (t_model % period) / period\n",
    "            mag_model_time = sinusoid(phase_t_model, A, phi0, mean_mag)\n",
    "\n",
    "            # Update y-limits\n",
    "            combined_mags = np.concatenate([mag, mag_model_phase, mag_model_time])\n",
    "            global_ymin = min(global_ymin, np.nanmin(combined_mags))\n",
    "            global_ymax = max(global_ymax, np.nanmax(combined_mags))\n",
    "\n",
    "            # Plot: time domain\n",
    "            axes[0].errorbar(time, mag, yerr=mag_err, fmt='o', label=f\"{band}-band\",\n",
    "                             alpha=0.6, color=band_colors.get(band, 'gray'), capsize=3)\n",
    "            axes[0].plot(t_model, mag_model_time, '--',\n",
    "                         label=f\"Fit ({band})\", color=band_colors.get(band, 'gray'))\n",
    "\n",
    "            # Plot: phase-folded\n",
    "            axes[1].errorbar(phase, mag, yerr=mag_err, fmt='o', label=f\"{band}-band\",\n",
    "                             alpha=0.6, color=band_colors.get(band, 'gray'), capsize=3)\n",
    "            axes[1].plot(phase_model, mag_model_phase, '--',\n",
    "                         label=f\"Fit ({band})\", color=band_colors.get(band, 'gray'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for object {object_id}, band {band}: {e}\")\n",
    "            continue\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.invert_yaxis()\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylabel(\"Magnitude\")\n",
    "\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    if period is not None:\n",
    "        plt.suptitle(f\"Object ID {object_id} / Period = {period:.4f} days\")\n",
    "    else:\n",
    "        plt.suptitle(f\"Object ID {object_id} / Period unknown\")\n",
    "\n",
    "    pad = 0.1 * (global_ymax - global_ymin)\n",
    "    axes[0].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "    axes[1].set_ylim(global_ymax + pad, global_ymin - pad)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id = RR_LSST_computed_long['diaObjectId_right'].unique()[0]\n",
    "# Get one object's lightcurve and period\n",
    "#object_id = RR_LSST_computed_long['objectId_right'].values[7]\n",
    "single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == object_id].copy()\n",
    "single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40575f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id = RR_LSST_computed_long['diaObjectId_right'].unique()[0]\n",
    "# Get one object's lightcurve and period\n",
    "#object_id = RR_LSST_computed_long['objectId_right'].values[7]\n",
    "single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == object_id].copy()\n",
    "single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]\n",
    "\n",
    "single_lc_with_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forced_sources.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57733dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = all_forced_sources[all_forced_sources['forcedSourceOnDiaObjectId'] == 24580707377481276]\n",
    "flag_columns = [col for col in all_forced_sources.columns if \"flag\" in col.lower()]\n",
    "\n",
    "outlier[flag_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafc8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forced_sources.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id = good_index[4]\n",
    "# Get one object's lightcurve and period\n",
    "#object_id = RR_LSST_computed_long['objectId_right'].values[7]\n",
    "single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == object_id].copy()\n",
    "single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]\n",
    "\n",
    "single_lc_with_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)  # or any number you prefer\n",
    "single_lc_with_columns[single_lc_with_columns['band'] =='u'][single_lc_with_columns[single_lc_with_columns['band'] =='u']['psfMag'] >19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forced_sources[all_forced_sources['forcedSourceOnDiaObjectId'] == 24580707377481276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b9142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mag_errors(86058.796875, 488.690796)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/test\"\n",
    "\n",
    "for object_id in good_index:\n",
    "    try:\n",
    "        # Extract the lightcurve\n",
    "        single_lc = all_forced_sources[all_forced_sources['diaObjectId'] == object_id].copy()\n",
    "\n",
    "        # Compute magnitude\n",
    "        single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "\n",
    "        # Select columns\n",
    "        selected = single_lc[[\n",
    "            'visit', 'coord_ra', 'coord_dec', 'tract', 'patch',\n",
    "            'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector',\n",
    "            'mjd', 'psfFlux', 'psfMag', 'band'\n",
    "        ]]\n",
    "\n",
    "        # Save to Parquet\n",
    "        output_path = f\"{output_dir}/w_18_objectId_{int(object_id)}.parquet\"\n",
    "        selected.to_parquet(output_path, index=False)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed for object {object_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810efdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0fa86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac71129",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = float(RR_LSST_computed_long[RR_LSST_computed_long['diaObjectId_right'] == int(object_id)]['PF_left'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ab4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long[RR_LSST_computed_long['diaObjectId_right'] == int(object_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be204b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit\tcoord_ra\tcoord_dec\ttract\tpatch\tforcedSourceOnDiaObjectId\tobjectId  detector, psfMag, MJD\n",
    "# popt  of the sinusoid fit in output per band too  \n",
    "# position of all RR Lyrae in the M49 field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae68e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', 'forcedSourceId', 'objectId', 'detector', 'mjd', 'psfFlux', 'psfMag', 'band' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_lc_with_columns.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_18_objectId_\"+str(int(single_lc_with_columns['objectId'].values[0]))).parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2c9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea8c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e36a31f",
   "metadata": {},
   "source": [
    "# Locations of all RRLyrae in M49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directory where the files are\n",
    "base_dir = Path(\"/sdf/home/n/ncaplar\")\n",
    "\n",
    "# List of filenames\n",
    "filenames = [\"212_m7.tsv\", \"216_m17.tsv\", \"m49.tsv\"]\n",
    "\n",
    "# Column names based on your file structure\n",
    "column_names = [\n",
    "    '_RAJ2000', '_DEJ2000', 'Source', 'PF', 'P1O',\n",
    "    'Gmagavg', 'RA_ICRS', 'DE_ICRS'\n",
    "]\n",
    "\n",
    "# Dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "for file in filenames:\n",
    "    file_path = base_dir / file\n",
    "    \n",
    "    # Read and find where the actual data starts\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('_RAJ2000|'):\n",
    "            start_idx = i\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        raise ValueError(f\"Could not find table header in {file}\")\n",
    "\n",
    "    data_start = start_idx + 3  # skip header + units + dashed lines\n",
    "\n",
    "    # Read the actual table\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=\"|\",\n",
    "        skiprows=data_start,\n",
    "        names=column_names,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "    dfs[file.replace(\".tsv\", \"\")] = df  # store with nice key like '212_m7'\n",
    "\n",
    "# Unpack individual DataFrames\n",
    "df_212_m7 = dfs[\"212_m7\"]\n",
    "df_216_m17 = dfs[\"216_m17\"]\n",
    "df_m49 = dfs[\"m49\"]\n",
    "\n",
    "# Example: print how many rows were loaded\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name}: {len(df)} rows loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_lc_with_columns.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_18_objectId_\"+str(int(single_lc_with_columns['objectId'].values[0]))).parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the locations of the RR Lyrae stars in the M49 field \n",
    "df_m49.to_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_18_objectId_RR_Lyrae_all_positions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e4ee2",
   "metadata": {},
   "source": [
    "# Fit with GAIA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86105f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_ids_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53670a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_ids_w19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f428f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_suffix_band = {\n",
    "    6808: [\"g\"],\n",
    "    6548: [\"r\"],\n",
    "    2537: [\"r\"],\n",
    "    3772: [\"r\"],\n",
    "    1651: [\"g\"],\n",
    "    6416: [\"u\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\"\n",
    "}\n",
    "\n",
    "# Loop over all object IDs\n",
    "for obj_id in intersect_ids_w19:\n",
    "    \n",
    "    obj_suffix = int(str(obj_id)[-4:])\n",
    "    if obj_suffix not in allowed_suffix_band:\n",
    "        continue\n",
    "\n",
    "    single_lc = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'] == obj_id].copy()\n",
    "\n",
    "    valid_bands = allowed_suffix_band[obj_suffix]\n",
    "    single_lc = single_lc[single_lc['band'].isin(valid_bands)]\n",
    "    if single_lc.empty:\n",
    "        continue\n",
    "    \n",
    "    #\n",
    "\n",
    "    # Remove flagged measurements\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))\n",
    "    single_lc = single_lc[flag_mask]\n",
    "\n",
    "    # Convert flux to magnitude\n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "\n",
    "    single_lc_with_columns = single_lc[['visit', 'coord_ra', 'coord_dec', 'tract', 'patch', \n",
    "                                        'forcedSourceOnDiaObjectId', 'diaObjectId', 'detector', \n",
    "                                        'mjd', 'psfFlux', 'psfMag', 'band']]\n",
    "    \n",
    "    single_lc_with_columns.to_parquet(\n",
    "        f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/GAIA/w_19_objectId_{int(obj_id)}_band_{band}.parquet\"\n",
    "    )\n",
    "\n",
    "    # Keep only u, g, r, i bands\n",
    "    single_lc = single_lc[single_lc['band'].isin([\"u\", \"g\", \"r\", \"i\"])]\n",
    "    if single_lc.empty:\n",
    "        continue\n",
    "\n",
    "    # Get Gaia-derived period and Fourier shape parameters\n",
    "    row = RR_LSST_computed_long_w19[\n",
    "        RR_LSST_computed_long_w19['diaObjectId_right'] == int(obj_id)\n",
    "    ]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        period = float(row['PF_left'].values[0])\n",
    "        R21 = float(row['R21G_left'].values[0])\n",
    "        R31 = float(row['R31G_left'].values[0])\n",
    "        phi21 = float(row['phi21G_left'].values[0])\n",
    "        phi31 = float(row['phi31G_left'].values[0])\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    # Set up plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    # Fit and plot each band separately\n",
    "    band_fit_results = {}\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        time = group[\"mjd\"].values.astype(float)\n",
    "        flux = group[\"psfFlux\"].values.astype(float)\n",
    "        flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "        mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "\n",
    "        if len(time) < 10 or np.any(np.isnan(mag)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            popt, model_func = fit_constrained_fourier(time, mag, mag_err, period, R21, R31, phi21, phi31)\n",
    "            band_fit_results[band] = (popt[0], popt[1], popt[2])\n",
    "        except Exception as e:\n",
    "            print(f\"Fit failed for {obj_id} in band {band}: {e}\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Time-domain model\n",
    "        t_model = np.linspace(np.min(time), np.max(time), 10000)\n",
    "        mag_fit_time = model_func((t_model % period) / period)\n",
    "\n",
    "        # Phase model\n",
    "        phase = (time % period) / period\n",
    "        phase_fit = np.linspace(0, 1, 5000)\n",
    "        mag_fit_phase = model_func(phase_fit)\n",
    "\n",
    "        # Evaluate model at observation phases\n",
    "        mag_model_phase = model_func(phase)\n",
    "\n",
    "        # Save full light curve (data + model evaluated at data points)\n",
    "        output_df = pd.DataFrame({\n",
    "            \"mjd\": time,\n",
    "            \"psfFlux\": flux,\n",
    "            \"psfFluxErr\": flux_err,\n",
    "            \"psfMag\": mag,\n",
    "            \"psfMagErr\": mag_err,\n",
    "            \"phase\": phase,\n",
    "            \"mag_model_phase\": mag_model_phase,\n",
    "            \"band\": band,\n",
    "            \"diaObjectId\": obj_id\n",
    "        })\n",
    "\n",
    "        output_df.to_parquet(\n",
    "            f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/GAIA/w_19_objectId_phase_fit_{int(obj_id)}_band_{band}.parquet\"\n",
    "        )\n",
    "\n",
    "        # Save time-domain model curve (dense)\n",
    "        model_time_df = pd.DataFrame({\n",
    "            \"t_model\": t_model,\n",
    "            \"mag_fit_time\": mag_fit_time,\n",
    "            \"band\": band,\n",
    "            \"diaObjectId\": obj_id\n",
    "        })\n",
    "        model_time_df.to_parquet(\n",
    "            f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/GAIA/w_19_time_fit_{int(obj_id)}_band_{band}.parquet\"\n",
    "        )\n",
    "\n",
    "        # Save phase-domain model curve (dense)\n",
    "        model_phase_df = pd.DataFrame({\n",
    "            \"phase_fit\": phase_fit,\n",
    "            \"mag_fit_phase\": mag_fit_phase,\n",
    "            \"band\": band,\n",
    "            \"diaObjectId\": obj_id\n",
    "        })\n",
    "        model_phase_df.to_parquet(\n",
    "            f\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/GAIA/w_19_phase_model_{int(obj_id)}_band_{band}.parquet\"\n",
    "        )\n",
    "\n",
    "\n",
    "        color = band_colors.get(band, \"gray\")\n",
    "        axes[0].errorbar(time, mag, yerr=mag_err, fmt='o', alpha=0.6, label=f\"{band}-band\", color=color)\n",
    "        axes[0].plot(t_model, mag_fit_time, '--', color=color)\n",
    "\n",
    "        axes[1].errorbar(phase, mag, yerr=mag_err, fmt='o', alpha=0.6, color=color)\n",
    "        axes[1].plot(phase_fit, mag_fit_phase, '--', color=color)\n",
    "\n",
    "        global_ymin = min(global_ymin, np.nanmin(mag))\n",
    "        global_ymax = max(global_ymax, np.nanmax(mag))\n",
    "\n",
    "    # Final plot formatting\n",
    "    if global_ymin == np.inf:\n",
    "        continue\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(global_ymax + 0.2, global_ymin - 0.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_ylabel(\"Magnitude\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    plt.suptitle(f\"diaObjectId {obj_id} | Period = {period:.5f} d\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Fit parameters for diaObjectId {obj_id} (Period = {period:.5f} d):\")\n",
    "    for band_label, (A0, A1, phi1) in band_fit_results.items():\n",
    "        print(f\"  {band_label}-band: A₀ = {A0:.3f}, A₁ = {A1:.3f}, ϕ₁ = {phi1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca78865",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cc356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6d977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6167647c",
   "metadata": {},
   "source": [
    "## Load and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da584aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Base directory where all parquet files are saved\n",
    "base_dir = \"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/w_19/GAIA/\"\n",
    "\n",
    "# Color map\n",
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\"\n",
    "}\n",
    "\n",
    "# Find all phase-fit files (observed data + model at data points)\n",
    "phase_obs_files = sorted(glob.glob(os.path.join(base_dir, \"w_19_objectId_phase_fit_*_band_*.parquet\")))\n",
    "\n",
    "for phase_obs_path in phase_obs_files:\n",
    "    base_name = os.path.basename(phase_obs_path)\n",
    "    obj_id = base_name.split(\"_\")[5]\n",
    "    band = base_name.split(\"_\")[7].replace(\".parquet\", \"\")\n",
    "\n",
    "    # Construct paths to time model and phase model files\n",
    "    time_model_path = os.path.join(base_dir, f\"w_19_time_fit_{obj_id}_band_{band}.parquet\")\n",
    "    phase_model_path = os.path.join(base_dir, f\"w_19_phase_model_{obj_id}_band_{band}.parquet\")\n",
    "\n",
    "    # Skip if required files are missing\n",
    "    if not os.path.exists(time_model_path) or not os.path.exists(phase_model_path):\n",
    "        print(f\"Missing model files for object {obj_id}, band {band}\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    df_obs = pd.read_parquet(phase_obs_path)\n",
    "    df_time_model = pd.read_parquet(time_model_path)\n",
    "    df_phase_model = pd.read_parquet(phase_model_path)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    color = band_colors.get(band, \"gray\")\n",
    "\n",
    "    # Time domain panel\n",
    "    axes[0].errorbar(df_obs[\"mjd\"], df_obs[\"psfMag\"], yerr=df_obs[\"psfMagErr\"],\n",
    "                     fmt='o', label=\"Observed\", color=color, alpha=0.6)\n",
    "    axes[0].plot(df_time_model[\"t_model\"], df_time_model[\"mag_fit_time\"], '--', color=color, label=\"Model\")\n",
    "\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_ylabel(\"Magnitude\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Phase-folded panel\n",
    "    df_obs_sorted = df_obs.sort_values(\"phase\")\n",
    "    df_phase_model_sorted = df_phase_model.sort_values(\"phase_fit\")\n",
    "\n",
    "    axes[1].errorbar(df_obs_sorted[\"phase\"], df_obs_sorted[\"psfMag\"], yerr=df_obs_sorted[\"psfMagErr\"],\n",
    "                     fmt='o', color=color, alpha=0.6, label=\"Observed\")\n",
    "    axes[1].plot(df_phase_model_sorted[\"phase_fit\"], df_phase_model_sorted[\"mag_fit_phase\"],\n",
    "                 '--', color=color, label=\"Model\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f\"diaObjectId {obj_id} | Band: {band}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1df68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac0978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1dfd797",
   "metadata": {},
   "source": [
    "# Sinus fit with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b23950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Band colors\n",
    "band_colors = {\n",
    "    \"u\": \"blue\", \"g\": \"green\", \"r\": \"red\", \"i\": \"brown\"\n",
    "}\n",
    "\n",
    "# Fit shared-phase Fourier model\n",
    "def fit_shared_phase_fourier(times, mags, mag_errs, bands, period):\n",
    "    unique_bands = np.unique(bands)\n",
    "    band_idx = {b: i for i, b in enumerate(unique_bands)}\n",
    "    band_indices = np.array([band_idx[b] for b in bands])\n",
    "\n",
    "    def model(t, *params):\n",
    "        phi1 = params[0]\n",
    "        A0_list = params[1:1+len(unique_bands)]\n",
    "        A1_list = params[1+len(unique_bands):]\n",
    "        phase = (t % period) / period\n",
    "        return np.array([\n",
    "            A0_list[i] + A1_list[i] * np.cos(2 * np.pi * phase[j] + phi1)\n",
    "            for j, i in enumerate(band_indices)\n",
    "        ])\n",
    "\n",
    "    A0_init = [np.mean(mags[bands == b]) for b in unique_bands]\n",
    "    A1_init = [0.2 for _ in unique_bands]\n",
    "    p0 = [0.0] + A0_init + A1_init\n",
    "\n",
    "    popt, _ = curve_fit(model, times, mags, p0=p0, sigma=mag_errs, absolute_sigma=True, maxfev=10000)\n",
    "\n",
    "    phi1 = popt[0]\n",
    "    A0_fit = dict(zip(unique_bands, popt[1:1+len(unique_bands)]))\n",
    "    A1_fit = dict(zip(unique_bands, popt[1+len(unique_bands):]))\n",
    "\n",
    "    return A0_fit, A1_fit, phi1\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for obj_id in intersect_ids_w19:  # Make sure this is defined\n",
    "    single_lc = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'] == obj_id].copy()\n",
    "\n",
    "    # Remove flagged rows\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))\n",
    "    single_lc = single_lc[flag_mask]\n",
    "\n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "\n",
    "    # Use only u, g, r, i bands\n",
    "    single_lc = single_lc[single_lc['band'].isin([\"u\", \"g\", \"r\", \"i\"])]\n",
    "    if single_lc.empty:\n",
    "        continue\n",
    "\n",
    "    # Extract period\n",
    "    row = RR_LSST_computed_long_w19[\n",
    "        RR_LSST_computed_long_w19['diaObjectId_right'] == int(obj_id)\n",
    "    ]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        period = float(row['PF_left'].values[0])\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    # Gather all bands for shared fit\n",
    "    times_all, mags_all, magerrs_all, bands_all = [], [], [], []\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        time = group[\"mjd\"].values.astype(float)\n",
    "        flux = group[\"psfFlux\"].values.astype(float)\n",
    "        flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "        mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "\n",
    "        if len(time) < 10:\n",
    "            continue\n",
    "\n",
    "        times_all.append(time)\n",
    "        mags_all.append(mag)\n",
    "        magerrs_all.append(mag_err)\n",
    "        bands_all.append(np.full_like(time, band, dtype=object))\n",
    "\n",
    "    if not times_all:\n",
    "        continue\n",
    "\n",
    "    # Concatenate for joint fit\n",
    "    time_all = np.concatenate(times_all)\n",
    "    mag_all = np.concatenate(mags_all)\n",
    "    magerr_all = np.concatenate(magerrs_all)\n",
    "    band_all = np.concatenate(bands_all)\n",
    "\n",
    "    # Fit\n",
    "    try:\n",
    "        A0_fit, A1_fit, phi1 = fit_shared_phase_fourier(time_all, mag_all, magerr_all, band_all, period)\n",
    "    except Exception as e:\n",
    "        print(f\"Fit failed for {obj_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    for band in A0_fit:\n",
    "        mask = (band_all == band)\n",
    "        t = time_all[mask]\n",
    "        m = mag_all[mask]\n",
    "        m_err = magerr_all[mask]\n",
    "        phase = ((t % period) / period)\n",
    "\n",
    "        color = band_colors.get(band, \"gray\")\n",
    "\n",
    "        # Plot time-domain\n",
    "        axes[0].errorbar(t, m, yerr=m_err, fmt='o', alpha=0.6, label=f\"{band}-band\", color=color)\n",
    "        t_model = np.linspace(t.min(), t.max(), 1000)\n",
    "        model_t = A0_fit[band] + A1_fit[band] * np.cos(2 * np.pi * ((t_model % period) / period) + phi1)\n",
    "        axes[0].plot(t_model, model_t, '--', color=color)\n",
    "\n",
    "        # Plot phase-folded\n",
    "        phase_model = np.linspace(0, 1, 500)\n",
    "        mag_model = A0_fit[band] + A1_fit[band] * np.cos(2 * np.pi * phase_model + phi1)\n",
    "        axes[1].errorbar(phase, m, yerr=m_err, fmt='o', alpha=0.6, color=color)\n",
    "        axes[1].plot(phase_model, mag_model, '--', color=color)\n",
    "\n",
    "        global_ymin = min(global_ymin, np.nanmin(m))\n",
    "        global_ymax = max(global_ymax, np.nanmax(m))\n",
    "\n",
    "    if global_ymin == np.inf:\n",
    "        continue\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(global_ymax + 0.2, global_ymin - 0.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_ylabel(\"Magnitude\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    plt.suptitle(f\"diaObjectId {obj_id} | Period = {period:.5f} d\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()\n",
    "\n",
    "    # Print fit summary\n",
    "    print(f\"Shared-phase fit for diaObjectId {obj_id} (Period = {period:.5f} d):\")\n",
    "    for band in A0_fit:\n",
    "        print(f\"  {band}-band: A₀ = {A0_fit[band]:.3f}, A₁ = {A1_fit[band]:.3f}\")\n",
    "    print(f\"  Shared ϕ₁ = {phi1:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255cc71",
   "metadata": {},
   "source": [
    "# Fit with Sesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73716880",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_LSST_computed_long_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/RR_LSST_computed_long_w19.parquet\")\n",
    "all_forced_sources_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/all_forced_sources_w19.parquet\")\n",
    "visit_ids_w19 = all_forced_sources_w19['visit'].unique()\n",
    "times_w19 = np.load('/sdf/home/n/ncaplar/rrlyrae_lightcurves/times_w19.npy')\n",
    "filtered_visits_df_w19 = pd.read_parquet(\"/sdf/group/rubin/shared/notebooks/mjuric/rfl/variable_objects/filtered_visits_df_w19.parquet\")\n",
    "visit_to_mjd_w19 = dict(zip(filtered_visits_df_w19['visit_id'], filtered_visits_df_w19['exp_midpt_mjd']))\n",
    "all_forced_sources_w19['mjd'] = all_forced_sources_w19['visit'].map(visit_to_mjd_w19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_ids_w19 = np.array([69261123651633168, 70922760599109657, 70922898038063320,\n",
    "       70927777120911374, 70930113583120389, 70934168032247856,\n",
    "       72578144074203143, 72582679559667755, 72584053949202435,\n",
    "       72584191388155907, 72585222180306950, 72585771936120856,\n",
    "       72586871447748649, 72591613091643426, 72597866564026416,\n",
    "       72598553758793772, 72601233818386462, 74238475351621651,\n",
    "       74239231265865808, 74240536935923747, 74241224130691109,\n",
    "       74241636447551510, 74242667239702537, 74243423153946646,\n",
    "       74244522665574414, 74246446810923009, 74247477603074095,\n",
    "       74247615042027587, 74249126870515732, 74249195589992487,\n",
    "       74252562844352545, 74255242903945239, 74256479854526548,\n",
    "       74257304488247305, 74258060402491403, 75889735658111016,\n",
    "       75894133704622084, 75895508094156808, 75896813764214861,\n",
    "       75897019922645015, 75897294800551970, 75897638397935633])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc625db",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('/sdf/home/n/ncaplar/templates/11*g.dat'))\n",
    "plt.figure()\n",
    "for f in files:\n",
    "    phase, amp = np.genfromtxt(f,unpack=True)\n",
    "    plt.plot(np.append(phase,phase+1),np.append(amp,amp), c='tab:green', label=f)\n",
    "plt.ylim(1.1,-0.1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fb921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "from functools import partial\n",
    "import glob\n",
    "\n",
    "band_colors = {\n",
    "    \"u\": \"blue\",\n",
    "    \"g\": \"green\",\n",
    "    \"r\": \"red\",\n",
    "    \"i\": \"brown\"\n",
    "}\n",
    "\n",
    "# Load all template files\n",
    "template_files = sorted(glob.glob('/sdf/home/n/ncaplar/templates/11*g.dat'))\n",
    "if not template_files:\n",
    "    raise RuntimeError(\"No template files found!\")\n",
    "\n",
    "def empirical_model_fit(phase, A0, A1, shift, amp_template, template_phase):\n",
    "    shifted_phase = (phase + shift) % 1.0\n",
    "    interp = interp1d(template_phase, amp_template, kind='linear', fill_value=\"extrapolate\")\n",
    "    return A0 + A1 * interp(shifted_phase)\n",
    "\n",
    "# Loop over all object IDs\n",
    "for obj_id in intersect_ids_w19:\n",
    "    single_lc = all_forced_sources_w19[all_forced_sources_w19['diaObjectId'] == obj_id].copy()\n",
    "    single_lc = single_lc[single_lc['band'].isin([\"u\", \"g\", \"r\", \"i\"])]\n",
    "    if single_lc.empty:\n",
    "        continue\n",
    "\n",
    "    # Remove flagged measurements\n",
    "    flag_cols = [col for col in single_lc.columns if 'flag' in col.lower()]\n",
    "    flag_mask = ~(single_lc[flag_cols].any(axis=1))\n",
    "    single_lc = single_lc[flag_mask]\n",
    "    single_lc['psfMag'] = create_mag(single_lc['psfFlux'])\n",
    "\n",
    "    # Get Gaia-derived period\n",
    "    row = RR_LSST_computed_long_w19[\n",
    "        RR_LSST_computed_long_w19['diaObjectId_right'] == int(obj_id)\n",
    "    ]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        period = float(row['PF_left'].values[0])\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    global_ymin = np.inf\n",
    "    global_ymax = -np.inf\n",
    "\n",
    "    for band, group in single_lc.groupby(\"band\"):\n",
    "        time = group[\"mjd\"].values.astype(float)\n",
    "        flux = group[\"psfFlux\"].values.astype(float)\n",
    "        flux_err = group[\"psfFluxErr\"].values.astype(float)\n",
    "        mag, mag_err = create_mag_errors(flux, flux_err)\n",
    "\n",
    "        if len(time) < 10 or np.any(np.isnan(mag)):\n",
    "            continue\n",
    "\n",
    "        phase = (time % period) / period\n",
    "\n",
    "        best_chi2 = np.inf\n",
    "        best_fit = None\n",
    "        best_template = None\n",
    "\n",
    "        for template_file in template_files:\n",
    "            try:\n",
    "                template_phase, amp_template = np.genfromtxt(template_file, unpack=True)\n",
    "                template_phase = template_phase % 1.0\n",
    "\n",
    "                fit_model = partial(empirical_model_fit, amp_template=amp_template, template_phase=template_phase)\n",
    "                init_guess = [np.median(mag), (np.max(mag) - np.min(mag)) / 2, 0.0]\n",
    "                bounds = ([-np.inf, 0, -0.5], [np.inf, 10, 0.5])\n",
    "\n",
    "                popt, _ = curve_fit(fit_model, phase, mag, p0=init_guess, sigma=mag_err, bounds=bounds)\n",
    "\n",
    "                # Compute reduced chi-squared\n",
    "                residuals = mag - fit_model(phase, *popt)\n",
    "                chi2 = np.sum((residuals / mag_err)**2)\n",
    "                dof = len(mag) - len(popt)\n",
    "                reduced_chi2 = chi2 / dof if dof > 0 else np.inf\n",
    "\n",
    "                if reduced_chi2 < best_chi2:\n",
    "                    best_chi2 = reduced_chi2\n",
    "                    best_fit = (popt, amp_template, template_phase)\n",
    "                    best_template = template_file\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if best_fit is None:\n",
    "            print(f\"All fits failed for {obj_id} in band {band}\")\n",
    "            continue\n",
    "\n",
    "        A0_fit, A1_fit, shift_fit = best_fit[0]\n",
    "        amp_template, template_phase = best_fit[1], best_fit[2]\n",
    "        fit_model = partial(empirical_model_fit, amp_template=amp_template, template_phase=template_phase)\n",
    "\n",
    "        # Evaluate model\n",
    "        phase_fit = np.linspace(0, 1, 500)\n",
    "        mag_fit_phase = fit_model(phase_fit, *best_fit[0])\n",
    "        t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "        mag_fit_time = fit_model((t_model % period) / period, *best_fit[0])\n",
    "\n",
    "        color = band_colors.get(band, \"gray\")\n",
    "        axes[0].errorbar(time, mag, yerr=mag_err, fmt='o', alpha=0.6, label=f\"{band}-band\", color=color)\n",
    "        axes[0].plot(t_model, mag_fit_time, '--', color=color)\n",
    "\n",
    "        axes[1].errorbar(phase, mag, yerr=mag_err, fmt='o', alpha=0.6, color=color)\n",
    "        axes[1].plot(phase_fit, mag_fit_phase, '--', color=color)\n",
    "\n",
    "        global_ymin = min(global_ymin, np.nanmin(mag))\n",
    "        global_ymax = max(global_ymax, np.nanmax(mag))\n",
    "\n",
    "        print(f\"Best template for {band}-band (diaObjectId {obj_id}):\")\n",
    "        print(f\"  File: {best_template}\")\n",
    "        print(f\"  A₀ = {A0_fit:.3f}, A₁ = {A1_fit:.3f}, shift = {shift_fit:.3f}, χ²_red = {best_chi2:.3f}\")\n",
    "\n",
    "    if global_ymin == np.inf:\n",
    "        continue\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(global_ymax + 0.2, global_ymin - 0.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_ylabel(\"Magnitude\")\n",
    "    axes[0].set_title(\"Time Domain\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_title(\"Phase Folded\")\n",
    "\n",
    "    plt.suptitle(f\"diaObjectId {obj_id} | Period = {period:.5f} d\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4155e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
