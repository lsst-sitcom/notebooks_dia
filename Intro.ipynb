{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import healpy as hp\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import lsst.daf.butler as dafButler\n",
    "from lsst.analysis.ap import apdb\n",
    "from lsst.ap.association import AssociationTask, AssociationConfig\n",
    "from lsst.dax.apdb import Apdb, ApdbCassandra, ApdbTables\n",
    "import lsst.geom\n",
    "from lsst.afw import image as afwImage\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy.visualization import ZScaleInterval, SqrtStretch, ImageNormalize, ManualInterval, AsinhStretch, MinMaxInterval, LogStretch\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from typing import TYPE_CHECKING, cast\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "plt.set_loglevel('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mag_errors(sciFlux, sciFluxErr):\n",
    "    \"\"\"Move flux into magnitudes and calculate the error on the magnitude\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sciFlux : `float`\n",
    "        Science flux\n",
    "    sciFluxErr : `float`\n",
    "        Science flux error\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mag, magerr  : `float`, `float`\n",
    "        Magnitude and magnitude error\n",
    "    \"\"\"\n",
    "    \n",
    "    mag = u.nJy.to(u.ABmag, sciFlux)\n",
    "    upper_mag = u.nJy.to(u.ABmag, sciFlux+sciFluxErr)\n",
    "    lower_mag = u.nJy.to(u.ABmag, sciFlux-sciFluxErr)\n",
    "    magErr = -(upper_mag-lower_mag)/2\n",
    "    \n",
    "    return mag, magErr\n",
    "\n",
    "def create_mag(sciFlux):\n",
    "    \"\"\"Move flux into magnitudes and calculate the error on the magnitude\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sciFlux : `float`\n",
    "        Science flux\n",
    "    sciFluxErr : `float`\n",
    "        Science flux error\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mag, magerr  : `float`, `float`\n",
    "        Magnitude and magnitude error\n",
    "    \"\"\"\n",
    "    \n",
    "    mag = u.nJy.to(u.ABmag, sciFlux)\n",
    "    \n",
    "    return mag\n",
    "\n",
    "def degrees_to_radians(degrees):\n",
    "    \"\"\"\n",
    "    Convert an angle from degrees to radians.\n",
    "\n",
    "    Parameters:\n",
    "    degrees (float): Angle in degrees.\n",
    "\n",
    "    Returns:\n",
    "    float: Angle in radians (unitless).\n",
    "    \"\"\"\n",
    "    # Convert the input degrees to radians\n",
    "    radians = (degrees * u.deg).to(u.rad)\n",
    "    \n",
    "    # Return the numerical value (without the unit)\n",
    "    return radians.value\n",
    "\n",
    "def radians_to_degrees(radians):\n",
    "    \"\"\"\n",
    "    Convert an angle from radians to degrees.\n",
    "\n",
    "    Parameters:\n",
    "    radians (float): Angle in radians.\n",
    "\n",
    "    Returns:\n",
    "    float: Angle in degrees (unitless).\n",
    "    \"\"\"\n",
    "    # Convert the input radians to degrees\n",
    "    degrees = (radians * u.rad).to(u.deg)\n",
    "    \n",
    "    # Return the numerical value (without the unit)\n",
    "    return degrees.value\n",
    "\n",
    "def flux_to_magnitude(df_single_flux_src):\n",
    "    \"\"\"Magic function that converts flux to magnitude\n",
    "\n",
    "    Args:\n",
    "        df_single_flux_src (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the zeropoints for each band\n",
    "    zeropoints = {\n",
    "        'u': 12.652350670009373,\n",
    "        'g': 14.689449213373276,\n",
    "        'r': 14.559501946792281,\n",
    "        'i': 14.378976834902065,\n",
    "        'z': 13.993052964496345,\n",
    "        'y': 13.017367314857484\n",
    "    }\n",
    "    \n",
    "    # Create an empty dictionary to hold magnitudes\n",
    "    mag_dict = {}\n",
    "    \n",
    "    # Apply the transformation for each band\n",
    "    for band in zeropoints.keys():\n",
    "        # Make sure the flux column for the band exists in the dataframe\n",
    "        if f'lsst_flux_{band}' in df_single_flux_src.columns:\n",
    "            flux_col = f'lsst_flux_{band}'\n",
    "            mag_col = f'mag_{band}'\n",
    "            \n",
    "            # Calculate magnitudes from flux: mag = zp - 2.5 * log10(flux)\n",
    "            # Handling zero or negative flux values to avoid invalid log10 operations\n",
    "            mag_dict[mag_col] = zeropoints[band] - 2.5 * np.log10(df_single_flux_src[flux_col].replace(0, np.nan))\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame and concatenate with the original dataframe\n",
    "    mag_df = pd.DataFrame(mag_dict)\n",
    "    \n",
    "    # Return the original dataframe with new magnitude columns\n",
    "    return pd.concat([df_single_flux_src, mag_df], axis=1)\n",
    "\n",
    "def estimate_purity_completness(df_obj, tru_obj, match_value = 1):\n",
    "    \"\"\"Estimate the purity and completness of the detected objects\n",
    "    \n",
    "        Parameters\n",
    "    ----------\n",
    "    obj4_field : `pd.dataframe`\n",
    "        Detected objects\n",
    "    tru_obj : `pd.dataframe`\n",
    "        True variable objects\n",
    "    match_value : `float`\n",
    "        matching radius in arcsec    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    purity, completeness  : `float`, `float`\n",
    "        Purity and completness\n",
    "    \"\"\"\n",
    "\n",
    "    # all of the diaObjects in a field\n",
    "    dia_obj_SC = SkyCoord(ra=df_obj['ra'].values*u.degree, dec=df_obj['dec'].values*u.degree) \n",
    "    # all of the variable objects in a field\n",
    "    tru_obj_SC = SkyCoord(ra=tru_obj['ra'].values*u.degree, dec=tru_obj['dec'].values*u.degree)\n",
    "    # match the observations to the truth\n",
    "    idx, d2d, d3d = tru_obj_SC.match_to_catalog_sky(dia_obj_SC)\n",
    "    # index of all diaObj that are within match_value of a true variable object\n",
    "    idx_close = idx[d2d.to(u.arcsec).value<match_value]\n",
    "\n",
    "    # all of diaObjects thare are within match_value of a variable object\n",
    "    matches_close = df_obj.iloc[idx_close]\n",
    "\n",
    "    # fraction of dia Objects that are actually near a variable objects \n",
    "    purity = len(matches_close)/len(df_obj)\n",
    "\n",
    "    # fraction of variable objects that have been detected \n",
    "    completnes = len(matches_close)/len(tru_obj_SC)\n",
    "\n",
    "    return purity, completnes\n",
    "\n",
    "def plotFlagImages(exp, flagList=['DETECTED_NEGATIVE', 'DETECTED', 'SENSOR_EDGE', 'INEXACT_PSF']):\n",
    "    \"\"\"\n",
    "    Plot an image with associated mask flags to visualize flagged regions in astronomical imaging data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    exp : lsst.afw.image.ExposureF\n",
    "        The exposure object containing the image and associated mask to visualize.\n",
    "    \n",
    "    flagList : list of str, optional\n",
    "        A list of mask plane names to plot. These correspond to specific mask bits in the exposure mask.\n",
    "        Default is ['DETECTED_NEGATIVE', 'DETECTED', 'SENSOR_EDGE', 'INEXACT_PSF'].\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays a figure with subplots, where the first subplot shows the main image \n",
    "        (using ZScale normalization and square root stretch), and the subsequent subplots\n",
    "        display binary masks for the specified flags.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The first subplot visualizes the `exp.image.array` with a grayscale colormap.\n",
    "    - Each additional subplot shows a binary image highlighting pixels flagged with the specified mask planes.\n",
    "    - The function utilizes `ImageNormalize` with `ZScaleInterval` and `SqrtStretch` for the main image visualization.\n",
    "    - The function suppresses axis tick labels for cleaner visualization.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(24,8))\n",
    "    #plt.suptitle(dataId)\n",
    "    fig.add_subplot(1, len(flagList)+1, 1)\n",
    "    norm = ImageNormalize(exp.image.array, interval=ZScaleInterval(), stretch=SqrtStretch())\n",
    "    im = plt.imshow(exp.image.array, origin='lower', norm=norm, cmap='gray')\n",
    "    plt.gca().axes.xaxis.set_ticklabels([])\n",
    "    plt.gca().axes.yaxis.set_ticklabels([])\n",
    "    plt.title('diffim')\n",
    "    i = 1\n",
    "    for (name, bit) in exp.mask.getMaskPlaneDict().items():\n",
    "        if name in flagList:\n",
    "            \n",
    "            fig.add_subplot(1, len(flagList)+1, i + 1)\n",
    "            im = plt.imshow(np.where(exp.mask.array & 2**bit, 1, 0),\n",
    "                       origin='lower', cmap='GnBu', interpolation='nearest')\n",
    "            plt.title(name)\n",
    "            plt.gca().axes.xaxis.set_ticklabels([])\n",
    "            plt.gca().axes.yaxis.set_ticklabels([])\n",
    "            i = i + 1\n",
    "            del im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import truth tables from OR4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = 7436\n",
    "i2 = 7565\n",
    "\n",
    "# read the source catalogs\n",
    "# two pixels, one file for galaxies, one file for point sources\n",
    "df_single_ps1 = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/pointsource_'+str(i1)+'.parquet')\n",
    "df_single_ps2 = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/pointsource_'+str(i2)+'.parquet')\n",
    "df_single_gal1 = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/galaxy_'+str(i1)+'.parquet')\n",
    "df_single_gal2 = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/galaxy_'+str(i2)+'.parquet')\n",
    "# Concatenate the dataframes\n",
    "df_single_ps = pd.concat([df_single_ps1, df_single_ps2], ignore_index=True)\n",
    "df_single = pd.concat([df_single_ps1, df_single_ps2, df_single_gal1, df_single_gal2], ignore_index=True)\n",
    "\n",
    "# fluxes for these sources are in separate files\n",
    "df_single_ps1_flux = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/pointsource_flux_'+str(i1)+'.parquet')\n",
    "df_single_ps2_flux = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/pointsource_flux_'+str(i2)+'.parquet')\n",
    "df_single_gal1_flux = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/galaxy_flux_'+str(i1)+'.parquet')\n",
    "df_single_gal2_flux = pd.read_parquet('/sdf/data/rubin/shared/ops-rehearsals/ops-rehearsal-4/imSim_catalogs/skyCatalogs/galaxy_flux_'+str(i2)+'.parquet')\n",
    "# Concatenate the dataframes\n",
    "df_single_ps_flux = pd.concat([df_single_ps1_flux, df_single_ps2_flux], ignore_index=True)\n",
    "df_single_flux = pd.concat([df_single_ps1_flux, df_single_ps2_flux, df_single_gal1_flux, df_single_gal2_flux], ignore_index=True)\n",
    "\n",
    "# select the variable sources\n",
    "df_single_ps_var = df_single_ps[df_single_ps['is_variable']==True]\n",
    "\n",
    "# limit our analyis to a small region of the sky\n",
    "ra_min =215.60\n",
    "ra_max = 216.40\n",
    "dec_min = -12.90\n",
    "dec_max = -12.15\n",
    "\n",
    "# Apply the filter to the dataframe, to get one spatial region - select variable sources\n",
    "tru_var_obj = df_single_ps_var[\n",
    "    (df_single_ps_var['ra'] >= ra_min) & (df_single_ps_var['ra'] <= ra_max) &\n",
    "    (df_single_ps_var['dec'] >= dec_min) & (df_single_ps_var['dec'] <= dec_max)]\n",
    "\n",
    "# Apply the filter to the dataframe, to get one spatial region - select all sources\n",
    "all_obj = df_single[\n",
    "    (df_single['ra'] >= ra_min) & (df_single['ra'] <= ra_max) &\n",
    "    (df_single['dec'] >= dec_min) & (df_single['dec'] <= dec_max)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query APDB (alert production database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'embargo_or4'\n",
    "instrument = 'LSSTComCamSim'\n",
    "\n",
    "############################################\n",
    "pp_collections_1 = ['LSSTComCamSim/prompt/output-2024-06-25', 'LSSTComCamSim/prompt/output-2024-06-26', 'LSSTComCamSim/prompt/output-2024-06-27']\n",
    "schema_1 =  f'pp_ppdb_lsstcomcamsim_or4'\n",
    "\n",
    "pp_collections_2 = 'u/sullii/DM-46333/OR4/association'\n",
    "schema_2 = 'pp_ppdb_dm46333F2'\n",
    "\n",
    "pp_collections_3 = 'u/sullii/DM-46333/OR4/databaseTimeoutFix_with_forcedSourceLimit'\n",
    "schema_3 = f'jeremym_ppdb_replication_test_3'\n",
    "############################################\n",
    "\n",
    "\n",
    "pp_collections = pp_collections_3\n",
    "schema = schema_3\n",
    "\n",
    "butler = dafButler.Butler(repo, collections=pp_collections, instrument=instrument)\n",
    "registry = butler.registry\n",
    "# skymap = butler.get(\"skyMap\", collections=collections, skymap=\"ops_rehersal_prep_2k_v1\")\n",
    "apdbQuery = apdb.ApdbPostgresQuery(instrument=instrument, namespace=schema)\n",
    "\n",
    "pp_butler = dafButler.Butler(repo, collections=pp_collections, instrument=instrument)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
